{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python365jvsc74a57bd0b0206a2614c586ab84eeefff9036d762a2b39dcc109d6e1d805eeb76c501de26",
   "display_name": "Python 3.6.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "https://analyticsindiamag.com/hands-on-guide-to-gansynth-an-adversarial-neural-audio-synthesis-technique/ "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "���� ������ �ùٸ��� �ʽ��ϴ�.\n",
      "���� ������ �ùٸ��� �ʽ��ϴ�.\n",
      "���� ������ �ùٸ��� �ʽ��ϴ�.\n",
      "���� ������ �ùٸ��� �ʽ��ϴ�.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Warning: Failed to create the file /content/gansynth/midi/bach.mid: No such \n",
      "Warning: file or directory\n",
      "\n",
      " 23  4922   23  1171    0     0   1171      0  0:00:04 --:--:--  0:00:04  1742\n",
      "curl: (23) Failed writing body (0 != 1171)\n"
     ]
    }
   ],
   "source": [
    " #Copy data from the GCS (Google Cloud Storage)\n",
    " !rm -r /content/gansynth &>/dev/null\n",
    " !mkdir /content/gansynth\n",
    " !mkdir /content/gansynth/midi\n",
    " !mkdir /content/gansynth/samples\n",
    " # Load default MIDI (Bach Prelude)\n",
    " #’curl’ command enables fetching a given URL \n",
    " !curl -o /content/gansynth/midi/bach.mid http://www.jsbach.net/midi/cs1-1pre.mid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-33-f66af2dd6a54>, line 3)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-33-f66af2dd6a54>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    http://storage.googleapis.com/magentadata/papers/gansynth/midi/arp.mid\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " SONG = '/content/gansynth/midi/bach.mid'\n",
    " !curl -o /content/gansynth/midi/riff-default.mid \n",
    " http://storage.googleapis.com/magentadata/papers/gansynth/midi/arp.mid\n",
    " RIFF = '/content/gansynth/midi/riff-default.mid'\n",
    " !pip install -q -U magenta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sucess\n"
     ]
    }
   ],
   "source": [
    "import os #module for interacting with the operating system\n",
    " #To load files from local device (weblink)\n",
    " # #  from google.colab import files \n",
    "import librosa #Python library for music and audio analysis\n",
    "from magenta.models.nsynth.utils import load_audio\n",
    "from magenta.models.gansynth.lib import flags as lib_flags\n",
    "from magenta.models.gansynth.lib import generate_util as gu\n",
    "from magenta.models.gansynth.lib import model as lib_model\n",
    "from magenta.models.gansynth.lib import util\n",
    "import matplotlib.pyplot as plt #for visualization\n",
    "import note_seq\n",
    "from note_seq.notebook_utils import colab_play as play\n",
    "#colab_play() inserts an HTML audio widget to play a sound in colab\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "#disable_v2_behavior() switches all global behaviors which vary between  \n",
    "#tensorflow 1.x and 2.x versions to behave as in 1.x.\n",
    "tf.disable_v2_behavior()  \n",
    "print(\"sucess\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload():\n",
    "    map = files.upload() #Upload the file \n",
    "    list = [] #Initialize list to store names of uploaded files\n",
    "    #Use iteritems() to iterate over key-value pairs of the dictionary of uploaded file content\n",
    "    for key, val in map.iteritems():\n",
    "        filename = os.path.join('/content/gansynth/midi', key)\n",
    "        with open(filename, 'w') as file: #open the file in write mode\n",
    "        #write the content of uploaded file to the specified file\n",
    "            file.write(val) \n",
    "            print('Writing the file {}'.format(filename))\n",
    "            list.append(filename) #Add the filename to the list \n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoint directory\n",
    "CHECKPOINT_DIR = 'E:\\\\nmb\\\\nmb_data\\\\cp\\\\'\n",
    "OP_DIR = 'E:\\\\nmb\\\\nmb_data\\\\samples' #output directory\n",
    "BATCH_SIZE = 16\n",
    "SR = 16000 #SR stands for Sample Rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expand the path of parent directory using expand_path()\n",
    "OP_DIR = util.expand_path(OP_DIR)\n",
    "#tensorflow.gfile.Exists() determines existence of a file\n",
    "if not tf.gfile.Exists(OP_DIR):\n",
    "#Create a directory using tensorflow.gfile.MakeDirs()\n",
    "    tf.gfile.MakeDirs(OP_DIR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Warning! Couldn't load model flags from experiment.json\n'utf-8' codec can't decode byte 0xc1 in position 80: invalid start byte\n\tadam_beta1: 0.0\n\tadam_beta2: 0.99\n\taudio_length: 64000\n\tbatchSizeSchedule: [16]\n\tbatch_size_schedule: [16, 8]\n\td_fn: specgram\n\tdata_normalizer: specgrams_prespecified_normalizer\n\tdata_type: mel\n\tdataset_name: nsynth_tfds\n\tdebug_hook: False\n\tdiscriminator_ac_loss_weight: 1.0\n\tdiscriminator_learning_rate: 0.0004\n\tfake_batch_size: 16\n\tfmap_base: 512\n\tfmap_decay: 1.0\n\tfmap_max: 128\n\tg_fn: specgram\n\tgen_gl_consistency_loss_weight: 0.0\n\tgenerator_ac_loss_weight: 1.0\n\tgenerator_learning_rate: 0.0004\n\tgradient_penalty_target: 1.0\n\tgradient_penalty_weight: 10.0\n\tkernel_size: 3\n\tlatent_vector_size: 256\n\tmag_normalizer_a: 0.0661371661726\n\tmag_normalizer_b: 0.113718730221\n\tmaster: \n\tnormalizer_margin: 0.8\n\tnormalizer_num_examples: 1000\n\tnum_resolutions: 7\n\tp_normalizer_a: 0.8\n\tp_normalizer_b: 0.0\n\tps_tasks: 0\n\treal_score_penalty_weight: 0.001\n\tsample_rate: 16000\n\tsave_summaries_num_images: 100\n\tscale_base: 2\n\tscale_mode: ALL\n\tsimple_arch: False\n\tstable_stage_num_images: 32\n\tstart_height: 4\n\tstart_width: 8\n\ttask: 0\n\ttfdsData: gs://tfds-data/datasets\n\tto_rgb_activation: tanh\n\ttotal_num_images: 320\n\ttrain_data_path: /tmp/gansynth/nsynth-train.tfrecord\n\ttrain_progressive: True\n\ttrain_root_dir: E:\\nmb\\nmb_data\\cp\n\ttrain_time_limit: None\n\ttrain_time_stage_multiplier: 1.0\n\ttransition_stage_num_images: 32\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "No stage folders found, is E:\\nmb\\nmb_data\\cp the correct model path?",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-6ed5c88ff550>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m })\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#Create a GAN model using flags and weights from a saved model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCHECKPOINT_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\pj21\\lib\\site-packages\\magenta\\models\\gansynth\\lib\\model.py\u001b[0m in \u001b[0;36mload_from_path\u001b[1;34m(cls, path, flags)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtrain_sub_dirs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m       raise ValueError('No stage folders found, is %s the correct model path?'\n\u001b[1;32m--> 168\u001b[1;33m                        % path)\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;31m# Get last checkpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[0mlast_stage_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_sub_dirs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No stage folders found, is E:\\nmb\\nmb_data\\cp the correct model path?"
     ]
    }
   ],
   "source": [
    "#Clear the default graph stack and reset the global default graph\n",
    "tf.reset_default_graph() \n",
    "myflags = lib_flags.Flags({\n",
    "#Dictionary for storing and accessing flags\n",
    "    'batchSizeSchedule': [BATCH_SIZE],\n",
    "    'tfdsData': \"gs://tfds-data/datasets\",\n",
    "})\n",
    "#Create a GAN model using flags and weights from a saved model\n",
    "model = lib_model.Model.load_from_path(CHECKPOINT_DIR, myflags) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}